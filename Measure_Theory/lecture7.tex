%! TeX root = ./main.tex
Let $(X,\mathscr{F},P)$ be a probability space,
$A_1,A_2,\dots\in \mathscr{F}$.
We define the \vocab{tail $\sigma$-algebra} $\mathscr{T}$ :
\[
\mathscr{G}_n := \sigma(\{A_{n+1},A_{n+2},\dots\}),
\quad \mathscr{T}:= \bigcap_{n=1}^\infty \mathscr{G}_n.
\]
Let $f_1,f_2,\dots$ be random variable, the tail $\sigma$-algebra
generated by them is defined similarly:
\[
\mathscr{G}_n:=\sigma(\{f_{n+1},f_{n+2},\dots\}),\quad
\mathscr{T}:=\bigcap_{n=1}^\infty \mathscr{G}_n.
\]

\begin{theorem}[Kolmogorov's 0-1 law]
    If $ A_1,A_2,\dots\in \mathscr{F}$ are independent, then $P(A) \in \{0,1\}$,
	$\forall A\in \mathscr{T}$.
\end{theorem}
\begin{proof}[Proof]
    Let $\mathscr{F}_n := \sigma(\{A_1,\dots,A_n\})$ and $\mathscr{G}_n$.
	They are clearly independent.

	Note that $\mathscr{A} := \bigcup_{n=1}^\infty \mathscr{F}_n$ is an algebra.

	Let $\mathscr{H}:=\sigma(\mathscr{A}) \supseteq \mathscr{G}_n \supseteq \mathscr{T}$.

	Hence $\forall A\in \mathscr{T}\subset \mathscr{H}$, $\forall \varepsilon>0$,
	exists  $B\in \mathscr{A}$ s.t. $P(A\Delta B)<\varepsilon$,
	so
	\[
	P(A)-P(AB)\le \varepsilon,\quad |P(A)-P(B)|\le \varepsilon.
	\]
	Since $B\in \mathscr{F}_n$ for some $n$, thus it is independent to $A$.
	\[
	|P(A)-P(A)^2|\le |P(A)-P(AB)|+|P(AB)-P(A)^2|\le 2\varepsilon.
	\]
	Let $\varepsilon \to 0$, we'll get  $P(A)\in \{0,1\}$.
\end{proof}
\begin{remark}
    When $A_i$'s are replace by random variables, this theorem also holds.
\end{remark}

\begin{example}
    finite Markov chain
\end{example}

\subsection{The completion of measure spaces}
\label{sub:The completion of measure spaces}
Let $(X,\mathscr{F},\mu)$ be a measure space, and
\[
	\widetilde{\mathscr{F}}:= \{A\cup N: A\in \mathscr{F}, \exists B\in \mathscr{F}
	\ s.t.\ \mu(B) = 0, N \subset B\}.
\]
Another way to define it is: $\widetilde{\mathscr{F}}:=\{A\backslash N\}$,
since
\[
A\cup N = A + NA^c = (A\cup B)\backslash (BA^c \backslash N);
\]
\[
A\backslash N = A - NA = (A\backslash B) + (BA\backslash N).
\]
In fact, we can do even more: $\widetilde{\mathscr{F}}:=\{A\Delta N\}$.

Next we define the measure
\[
	\widetilde{\mu}(A\cup N) := \mu(A),\quad \forall A\cup N\in \widetilde{\mathscr{F}}
\]
We need to check several things:
\begin{itemize}
	\item $\widetilde{\mathscr{F}}$ is a $\sigma$-algebra.
	\item $\widetilde{\mu}$ is well-defined.
	\item $(X, \widetilde{\mathscr{F}}, \widetilde{\mu})$ is a complete
		measure space.
\end{itemize}
\begin{remark}
    The mesure $\widetilde{\mu}$ is the \textit{minimal complete extension}
	of $\mu$, i.e. if $(X,\mathscr{G},\nu)$ is another complete extension,
	then
	\[
	\nu(B)=\mu(B)=0 \implies \forall N \subset B, N\in \mathscr{G}, \nu(N) = 0.
	\]
	\[
	\mu(A)=\nu(A)\le \nu(A\cup N)\le \nu(A) + \nu(N) = \nu(A).
	\]
	Thus $\mathscr{G}\supseteq \widetilde{\mathscr{F}}$ and $\nu(A)=\widetilde{\mu}(A)$
	for $A\in \widetilde{\mathscr{F}}$.

	Therefore we call $(X,\widetilde{\mathscr{F}},\widetilde{\mu})$ the
	\vocab{completion} of $(X,\mathscr{F},\mu)$.
\end{remark}

Obviously $\emptyset\in \widetilde{\mathscr{F}}$ ;
For $A\cup N\in \widetilde{\mathscr{F}}$,
$(A\cup N)^c = A^c - A^cN\in \widetilde{\mathscr{F}}$.

\[
\bigcup_{n=1}^\infty (A_n\cup N_n)=\bigcup_{n=1}^\infty A_n \cup \bigcup_{n=1}^\infty N_n,
\quad N = \bigcup_{n=1}^\infty N_n \subset \bigcup_{n=1}^\infty B_n.
\]
Thus $\widetilde{\mathscr{F}}$ is a $\sigma$-algebra.

For  $\widetilde{\mu}$, if $A_1\cup N_1=A_2\cup N_2$,
\[
\mu(A_1)=\mu(A_1\cup B_2)\ge \mu(A_2).
\]

Last we prove the countable additivity of $\widetilde{\mu}$.
It's easy to check, so left out.

For the completeness, if $C \subset A\cup N, \mu(A)=0$,
then $C \subset A\cup B$ which is null.

Combining with the previous results we have
\begin{theorem}
    Let $\tau$ be the outer measure generated by $\mu$,
	a $\sigma$-finite measure on a semi-ring $ \mathscr{Q}$.
	We have $(X \mathscr{F}_\tau,\tau)$ is
	the completion of $(X,\sigma(\mathscr{Q}), \tau)$.
\end{theorem}
\begin{proof}[Proof]
    Let $\mathscr{F} = \sigma(\mathscr{Q})$, we'll prove that
	$\widetilde{\mathscr{F}} = \mathscr{F}_\tau$.

	Since $(X,\mathscr{F}_\tau,\tau)$ is complete, we have $\mathscr{F}_\tau
	\supseteq \widetilde{\mathscr{F}}$.

	For all $C\in \mathscr{F}_\tau$, it suffices to
	prove $C = A+N$ for some
	$A\in \mathscr{F}, N \subset B$ with $B$ null.

	Since $C^c\in \mathscr{F}_\tau$, $\exists B\in \mathscr{F}$ s.t.
	\[
	B\supseteq C^c,\quad \tau(B\backslash C^c) = 0.
	\]
\end{proof}

\subsection{Distributions}
\label{sub:Distributions}

Let $F: \mathbb{R}\to \mathbb{R}$ be a non-decreasing, right continuous
function (called a \vocab{quasi-distribution function}).
Let $\nu$ be the measure on $\mathscr{Q}_{\mathbb{R}}$,
\[
	\nu : (a,b] \mapsto \max\{F(b)-F(a), 0\}.
\]
Let $\tau$ be the outer measure generated by $\nu$. 
We call the sets in $\mathscr{F}_\tau$ to be the Lebesgue-Stieljes
measurable sets (L-S measurable), a measurable function
\[
f: (\mathbb{R}, \mathscr{F}_\tau)\to
(\mathbb{R}, \mathscr{B}_{\mathbb{R}})
\]
is L-S measurable, and $\tau\big|_{\mathscr{F}_\tau}$
is the L-S measure.

In fact finite L-S measures and the quasi-distribution functions are 1-1
correspondent (ignoring the difference of a constant),
since $\mathscr{B}_{\mathbb{R}}=\sigma(\mathscr{Q}_{\mathbb{R}})$,
$(\mathbb{R},\mathscr{F}_\tau,\tau)$ is the completion of
$(\mathbb{R}, \mathscr{B}_{\mathbb{R}},\tau)$,
and $\mu_F = \tau\big|_{\mathscr{B}_{\mathbb{R}}}$ is the
unique extension of $\nu$. 

Conversely, given a measure $\mu$ on
$(\mathbb{R}, \mathscr{B}_{\mathbb{R}})$,
if $\mu((a,b])<\infty$ for all $a<b$, then  $\mu=\mu_F$, where
\[
	 F = F_\mu : x \mapsto \mu((-\infty,x]), \quad x\in \mathbb{R}.
\]

We say a probability measure on $(\mathbb{R}, \mathscr{B}_{\mathbb{R}})$ is
a \vocab{distribution}.
Let $F: \mathbb{R}\to \mathbb{R}$ be a quasi-distribution function,
if $F$ satisfies:
 \[
F(-\infty) := \lim_{x\to -\infty}F(x) = 0,\quad
F(+\infty):=\lim_{x\to +\infty}F(x) = 1,
\]
then we say $F$ is a distribution function (d.f.).

From the previous example we know distribution
and d.f. are one-to-one correspondent.

\begin{theorem}
    Let $g: (X,\mathscr{F})\to (Y, \mathscr{S})$, $\mu$ is a measure on $ \mathscr{F}$.
	Let
	\[
	\nu(B):=\mu(g^{-1}(B)) = \mu\circ g^{-1}(B),\quad \forall B\in \mathscr{S}.
	\]
	Then  $\nu$ is a measure on $\mathscr{S}$.
\end{theorem}
\begin{proof}[Proof]
    Trivial. Just check the definition one by one.
\end{proof}

Let $(\Omega, \mathscr{F}, P)$ be a probability space, $f:(\Omega, \mathscr{F})
\to (\mathbb{R}, \mathscr{B}_{\mathscr{R}})$. We say
\[
P\circ f^{-1} : B\mapsto P(f\in B)
\]
is the \vocab{distribution} of $f$, denoted by $\mu_f$, i.e.
$\mu_f(B) = P(f\in B)$ for Borel sets $B$.

If $\mu_f = \mu$, we say $f$ obeys the distribution $\mu$, denoted by
$f\sim \mu$. 

Let $F_f = F_{\mu_f}$ be the distribution function of $f$.
 \[
	 F_f := \mu_f ((-\infty,x]) = P(f\le x),\quad x\in \mathbb{R}.
\]
We can also say $f$ obeys $F_f$, denoted by $f\sim F_f$.

If $F_f = F_g$, then we say $f$ and $g$ is \vocab{equal in distribution},
denoted by  $f \overset{d}{=} g$. 

\begin{theorem}
	Any d.f. is the distribution function of some random variable.
\end{theorem}
\begin{proof}[Proof]
	Let $\Omega = \mathbb{R}, \mathscr{F} = \mathscr{B}_{\mathbb{R}},
	P=\mu_F$, and $f = \id$.
	It's clear that the distribution function of $f$ is precisely $F$.
\end{proof}
